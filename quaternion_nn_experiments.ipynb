{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quaternion_nn_experiments.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eretis/Pytorch-Quaternion-Neural-Networks/blob/master/quaternion_nn_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8BnKrCgT_BLJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Presentation \n",
        "\n",
        "** Goal:** Test the effectiveness of Group Sparse Regularization on Quaternion Neural Networks\n",
        "\n",
        "** Datasets:**\n",
        "\n",
        "           MNIST    http://yann.lecun.com/exdb/mnist/ \n",
        "           CIFAR10  https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        " **Paper:**   Group Sparse Regularization for Deep Neural Networks\n",
        "         https://arxiv.org/pdf/1607.00485.pdf\n",
        "\n",
        "**Author: ** Riccardo Vecchi\n",
        "\n",
        "**Version:** 1.0\n",
        "\n",
        "---\n",
        "\n",
        "#Guide\n",
        "\n",
        "1.   Clone the repository in the Colab's runtime with the \"Clone repository\" cell\n",
        "2.   Use the form for setting parameters and hyper-parameters and run cell\n",
        "3.   Good testing :-)\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "NDIqYU5eu-na",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Manage repository"
      ]
    },
    {
      "metadata": {
        "id": "CwdqbV6NxZmV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Clone repository"
      ]
    },
    {
      "metadata": {
        "id": "1798o2EQra4V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/eretis/Pytorch-Quaternion-Neural-Networks.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N0ehzOLmzQGs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Refresh repository"
      ]
    },
    {
      "metadata": {
        "id": "HvEl0wovxeB3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cd Pytorch-Quaternion-Neural-Networks && git pull\n",
        "!git pull\n",
        "%cd ../"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FUlfNXd3StGv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Delete repository"
      ]
    },
    {
      "metadata": {
        "id": "36ZRWSG9SwgU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf Pytorch-Quaternion-Neural-Networks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y7UrFzeNs4Yq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Run group_sparse_regularization_test.py"
      ]
    },
    {
      "metadata": {
        "id": "gh89CrkU-3Xv",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd Pytorch-Quaternion-Neural-Networks \n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "from quaternion_layers import *\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "\n",
        "#@markdown ##Parameters and Hyper-parameters\n",
        "\n",
        "# PARAMETERS #\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "dataset = 'MNIST' #@param ['CIFAR10', 'MNIST']\n",
        "use_quaternion_variant = True #@param {type: 'boolean'}\n",
        "plot_curve = True #@param {type: 'boolean'}\n",
        "debug = False #@param {type: 'boolean'}\n",
        "log_interval = 10\n",
        "\n",
        "# HYPER PARAMETERS #\n",
        "n_epochs = 30  #@param {type: 'number'}\n",
        "learning_rate = 0.001  #@param {type: 'number'}\n",
        "act_fn = F.selu #@param [\"F.relu\", \"F.selu\"] {type:\"raw\"}\n",
        "loss_criterion = F.cross_entropy  # before F.nll_loss (Negative log-likelihood loss)\n",
        "batch_size_train = 200 #@param {type: 'number'}\n",
        "batch_size_test = 1000 #@param {type: 'number'}\n",
        "regularization_factor = 0.035 #@param {type: 'number'}\n",
        "regularizer = 'Group L1'  #@param ['None', 'L1', 'L2', 'Group L1', 'Sparse GL1']\n",
        "\n",
        "\n",
        "\n",
        "CIFAR10_num_to_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "\n",
        "class MNISTQConvNet(nn.Module):  # Quaternion CNN for MNIST\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MNISTQConvNet, self).__init__()\n",
        "        # self.conv1 = nn.Conv2d(1, 4, kernel_size=5)  # input\n",
        "        self.conv2 = QuaternionConv(4, 8, kernel_size=5, stride=1, padding=1)\n",
        "        self.conv3 = QuaternionConv(8, 16, kernel_size=5, stride=1, padding=1)\n",
        "        self.conv3_drop1 = nn.Dropout2d()\n",
        "        self.fc1 = QuaternionLinear(400, 40)\n",
        "        # self.fc2 = QuaternionLinear(80, 40)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = F.relu(self.conv1(x))\n",
        "        x = act_fn(F.max_pool2d(self.conv2(x), 2))\n",
        "        x = act_fn(F.max_pool2d(self.conv3_drop1(self.conv3(x)), 2))\n",
        "        x = x.view(-1, 400)\n",
        "        x = act_fn(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = torch.reshape(x, (-1, 10, 4))\n",
        "        x = torch.sum(torch.abs(x), dim=2)\n",
        "        # x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def network_type(self):\n",
        "        return type(self).__name__\n",
        "\n",
        "\n",
        "class MNISTConvNet(nn.Module):  # Standard CNN for MNIST\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MNISTConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop1 = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 60)\n",
        "        self.fc2 = nn.Linear(60, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = act_fn(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = act_fn(F.max_pool2d(self.conv2_drop1(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = act_fn(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def network_type(self):\n",
        "        return type(self).__name__\n",
        "\n",
        "\n",
        "class CIFARQConvNet(nn.Module):  # Quaternion CNN for CIFAR-10\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CIFARQConvNet, self).__init__()\n",
        "        # self.conv1 = nn.Conv2d(1, 4, kernel_size=5)  # input\n",
        "        self.conv2 = QuaternionConv(4, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = QuaternionConv(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2_drop1 = nn.Dropout2d()\n",
        "        self.conv4 = QuaternionConv(64, 128, kernel_size=5, stride=1, padding=1)\n",
        "        self.conv5 = QuaternionConv(128, 256, kernel_size=5, stride=1, padding=1)\n",
        "        self.conv5_drop2 = nn.Dropout2d()\n",
        "        self.fc1 = QuaternionLinear(1024, 40)\n",
        "        # self.fc2 = nn.Linear(40, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = F.relu(self.conv1(x))\n",
        "        x = act_fn(F.max_pool2d(self.conv2(x), 2))\n",
        "        x = act_fn(F.max_pool2d(self.conv2_drop1(self.conv3(x)), 2))\n",
        "        x = act_fn(self.conv4(x))\n",
        "        x = act_fn(F.max_pool2d(self.conv5_drop2(self.conv5(x)), 2))\n",
        "        x = x.view(-1, 1024)\n",
        "        x = act_fn(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = torch.reshape(x, (-1, 10, 4))\n",
        "        x = torch.sum(torch.abs(x), dim=2)\n",
        "        # x = self.fc2(x) \n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def network_type(self):\n",
        "        return type(self).__name__\n",
        "\n",
        "\n",
        "class CIFARConvNet(nn.Module):  # Standard CNN for CIFAR-10\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CIFARConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2_drop1 = nn.Dropout2d()\n",
        "        self.conv3 = nn.Conv2d(16, 48, kernel_size=5, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(48, 92, kernel_size=5, stride=1, padding=1)\n",
        "        self.conv4_drop2 = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(368, 40)\n",
        "        self.fc2 = nn.Linear(40, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = act_fn(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = act_fn(F.max_pool2d(self.conv2_drop1(self.conv2(x)), 2))\n",
        "        x = act_fn(self.conv3(x))\n",
        "        x = act_fn(F.max_pool2d(self.conv4_drop2(self.conv4(x)), 2))\n",
        "        x = x.view(-1, 368)\n",
        "        x = act_fn(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    def network_type(self):\n",
        "        return type(self).__name__\n",
        "\n",
        "\n",
        "def get_dataset():\n",
        "    if dataset == 'CIFAR10':\n",
        "        transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
        "                                                    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "        data = torchvision.datasets.CIFAR10\n",
        "\n",
        "    elif dataset == 'MNIST':\n",
        "        transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
        "                                                    torchvision.transforms.Normalize((0.1307,), (\n",
        "                                                        0.3081,))])  # global mean and standard deviation for MNIST\n",
        "        data = torchvision.datasets.MNIST\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        data('/files/', train=True, download=True, transform=transform), batch_size=batch_size_train, shuffle=True)\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        data('/files/', train=False, download=True, transform=transform), batch_size=batch_size_test, shuffle=True)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "def count_trainable_parameters():\n",
        "    return sum(p.numel() for p in network.parameters() if p.requires_grad)\n",
        "  \n",
        "  \n",
        "def regularization(regularization_type=None):\n",
        "\n",
        "    reg = 0\n",
        "\n",
        "    if regularization_type == 'L1':\n",
        "      for param in network.parameters():\n",
        "        reg += torch.sum(torch.abs(param))\n",
        "                         \n",
        "    elif regularization_type == 'L2':\n",
        "      for param in network.parameters():\n",
        "        reg += torch.sum(param ** 2)\n",
        "\n",
        "    elif regularization_type == 'old Group L1':\n",
        "\n",
        "        square_mat_sum = None\n",
        "        \n",
        "        for param in network.parameters():\n",
        "          \n",
        "          if param.dim() > 1:  # avoid biases if exist (one-dimensional arrays)\n",
        "            if square_mat_sum is not None and square_mat_sum.shape != param.shape:\n",
        "              reg += torch.sum(torch.sqrt(square_mat_sum))\n",
        "              square_mat_sum = None\n",
        "            square_mat_sum = param ** 2 if square_mat_sum is None else square_mat_sum + param ** 2\n",
        "\n",
        "    elif regularization_type == 'Group L1':\n",
        "        for module in network.modules():\n",
        "            if module.__class__.__name__ == 'QuaternionConv' or module.__class__.__name__ == 'QuaternionLinear':\n",
        "                reg += torch.sum(torch.sqrt(module.r_weight ** 2 + module.i_weight ** 2 + module.j_weight ** 2 + module.k_weight ** 2))\n",
        "            #else:\n",
        "            #    for param in module.parameters():\n",
        "            #        reg += torch.sum(torch.abs(param))        \n",
        "            \n",
        "            \n",
        "    elif regularization_type == 'Sparse GL1':\n",
        "        reg += regularization('Group L1') + regularization('L1')\n",
        "\n",
        "    return reg\n",
        "\n",
        "\n",
        "def calculate_sparsity():\n",
        "\n",
        "    sparsity_weights, sparsity_neurons = [], []\n",
        "\n",
        "    for param in network.parameters():\n",
        "        \n",
        "        param = param.to('cpu').detach().numpy().round(decimals=3)\n",
        "\n",
        "        nonzero_weights = 1 - (param.ravel().nonzero()[0].shape[0] / param.size)\n",
        "        sparsity_weights.append(nonzero_weights)\n",
        "        \n",
        "        nonzero_neurons = param.sum(axis=0).nonzero()[0].shape[0]\n",
        "        sparsity_neurons.append(nonzero_neurons)\n",
        "\n",
        "    sparsity_weights = np.mean(sparsity_weights) * 100\n",
        "    sparsity_neurons = np.sum(sparsity_neurons)\n",
        "\n",
        "    return sparsity_weights, sparsity_neurons\n",
        "\n",
        "\n",
        "def expand_input(data, repeat_type='vector_RGB'):  # [BATCH X CHANNELS X WIDTH X HEIGHT]\n",
        "\n",
        "    if repeat_type == 'repeat':  # Copy the original input also for vector components (i, j, k)\n",
        "        new_input = np.repeat(data, 4, axis=1)\n",
        "\n",
        "    elif repeat_type == 'vector_zero':  # Zero-fill for vector components (i, j, k)\n",
        "        new_input = torch.zeros(data.shape[0], 4, data.shape[2], data.shape[3], dtype=torch.float, device=device)\n",
        "        new_input[:, :1, :, :] = data\n",
        "\n",
        "    elif repeat_type == 'vector_RGB':  # real part to 0 and (RGB) -> (i, j, k)\n",
        "        new_input = torch.zeros((data.shape[0], 4, data.shape[2], data.shape[3]), dtype=torch.float, device=device)\n",
        "        new_input[:, 1:, :, :] = data\n",
        "\n",
        "    if debug:\n",
        "        print('-----------------------')\n",
        "        np.set_printoptions(threshold=None)\n",
        "        print(data.shape)\n",
        "        print(new_input.shape)\n",
        "        print(new_input[0])\n",
        "\n",
        "    return new_input\n",
        "\n",
        "\n",
        "def train():\n",
        "\n",
        "    network.train()\n",
        "\n",
        "    # TRAIN LOOP #\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        test(epoch)\n",
        "        \n",
        "        weights, neurons = calculate_sparsity()\n",
        "        print('Checking sparsity...\\nSparsity {:.2f}%\\nNeurons: {}\\n'.format(weights, neurons))\n",
        "\n",
        "        for batch_index, (data, target) in enumerate(train_set):\n",
        "\n",
        "            if use_quaternion_variant:\n",
        "                data = expand_input(data, 'vector_RGB')\n",
        "\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = network(data)  # Forward pass\n",
        "            loss = loss_criterion(output, target) + regularization_factor * regularization(regularizer)\n",
        "            loss.backward()  # Backward pass\n",
        "            optimizer.step()  # Optimize\n",
        "\n",
        "            if batch_index % log_interval == 0:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch + 1, batch_index * len(data), len(train_set.dataset),\n",
        "                    100. * batch_index / len(train_set), loss.item()))\n",
        "                train_losses.append(loss.item())\n",
        "                train_counter.append((batch_index * batch_size_train) + (epoch * len(train_set.dataset)))\n",
        "\n",
        "    test(n_epochs)\n",
        "\n",
        "\n",
        "def test(epoch):\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_set:\n",
        "\n",
        "            if use_quaternion_variant:\n",
        "                data = expand_input(data, 'vector_RGB')\n",
        "\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            output = network(data)\n",
        "            test_loss += loss_criterion(output, target, reduction='sum').item()\n",
        "            pred = output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.detach().view_as(pred)).sum()\n",
        "    test_loss /= len(test_set.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "    test_counter.append(epoch * len(train_set.dataset))\n",
        "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_set.dataset),\n",
        "        100. * correct / len(test_set.dataset)))\n",
        "\n",
        "\n",
        "def inference(raw_image):\n",
        "    image_tensor = raw_image.unsqueeze_(0).to(device)\n",
        "    if use_quaternion_variant:\n",
        "        image_tensor = expand_input(image_tensor)\n",
        "    network.eval()\n",
        "    output = network(image_tensor)\n",
        "    index = torch.argmax(output).item()\n",
        "    index = CIFAR10_num_to_classes[index] if dataset == 'CIFAR10' else index\n",
        "    return index\n",
        "\n",
        "\n",
        "def show_image(image, text_ground_truth):\n",
        "    plt.tight_layout()\n",
        "    plt.subplot(2, 3, 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    image = np.transpose(image / 2 + 0.5, (1, 2, 0)) if dataset == 'CIFAR10' else image[0]\n",
        "    plt.imshow(image, cmap='gray', interpolation='nearest')\n",
        "\n",
        "    text_ground_truth = CIFAR10_num_to_classes[text_ground_truth] if dataset == 'CIFAR10' else text_ground_truth\n",
        "    plt.title('Ground Truth: {}'.format(text_ground_truth))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_training_curve():\n",
        "    plt.plot(train_counter, train_losses, color='blue')\n",
        "    plt.scatter(test_counter, test_losses, color='red')\n",
        "    plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
        "    plt.xlabel('Number of training examples seen')\n",
        "    plt.ylabel(loss_criterion.__name__.capitalize().replace('_', ' '))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "print('\\n*** Group Sparse Regularization Testing ***\\n')\n",
        "\n",
        "if use_quaternion_variant:\n",
        "    if dataset == 'MNIST':\n",
        "        network = MNISTQConvNet()\n",
        "    else:\n",
        "        network = CIFARQConvNet()\n",
        "else:\n",
        "    if dataset == 'MNIST':\n",
        "        network = MNISTConvNet()\n",
        "    else:\n",
        "        network = CIFARConvNet()\n",
        "        \n",
        "network = network.to(device)\n",
        "optimizer = optim.Adam(network.parameters(), lr=learning_rate)\n",
        "\n",
        "print('Device used: ' + device.type)\n",
        "print('Network variant: ' + network.network_type())\n",
        "print('Number of trainable parameters: {}\\n'.format(count_trainable_parameters()))\n",
        "\n",
        "print('Retrieve ' + dataset + ' dataset...\\n')\n",
        "train_set, test_set = get_dataset()\n",
        "\n",
        "train_counter, train_losses, test_counter, test_losses = [], [], [], []\n",
        "\n",
        "print('\\nStart training from ' + dataset + ' training set to generate the model...')\n",
        "print('Epochs: ' + str(n_epochs) + '\\nLearning rate: ' + str(learning_rate) + '\\n')\n",
        "\n",
        "start_time = time.time()\n",
        "train()\n",
        "print('Elapsed time: {:.2f} seconds\\n'.format(time.time()-start_time))\n",
        "\n",
        "weights, neurons = calculate_sparsity()\n",
        "print('Checking sparsity...\\nSparsity {:.2f}%\\nNeurons: {}\\n'.format(weights, neurons))\n",
        "\n",
        "samples = enumerate(test_set)\n",
        "batch_idx, (sample_data, sample_targets) = next(samples)\n",
        "\n",
        "print('Evaluation of a random sample: ' + str(inference(sample_data[0])))\n",
        "show_image(sample_data[0], sample_targets[0])  # Show a random image from the test set\n",
        "\n",
        "if plot_curve:\n",
        "    plot_training_curve()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}